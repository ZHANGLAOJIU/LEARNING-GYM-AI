{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d667c488",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25168/3185357286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgridworld\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCliffWalkingWapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFrozenLakeWapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQLearningAgent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "#   Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import gym\n",
    "from gridworld import CliffWalkingWapper, FrozenLakeWapper\n",
    "from agent import QLearningAgent\n",
    "import time\n",
    "assert gym.__version__ == \"0.18.0\", \"[Version WARNING] please try `pip install gym==0.18.0`\"\n",
    "\n",
    "\n",
    "def run_episode(env, agent, render=False):\n",
    "    total_steps = 0  # 记录每个episode走了多少step\n",
    "    total_reward = 0\n",
    "\n",
    "    obs = env.reset()  # 重置环境, 重新开一局（即开始新的一个episode）\n",
    "\n",
    "    while True:\n",
    "        action = agent.sample(obs)  # 根据算法选择一个动作\n",
    "        next_obs, reward, done, _ = env.step(action)  # 与环境进行一个交互\n",
    "        # 训练 Q-learning算法\n",
    "        agent.learn(obs, action, reward, next_obs, done)\n",
    "\n",
    "        obs = next_obs  # 存储上一个观察值\n",
    "        total_reward += reward\n",
    "        total_steps += 1  # 计算step数\n",
    "        if render:\n",
    "            env.render()  #渲染新的一帧图形\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward, total_steps\n",
    "\n",
    "\n",
    "def test_episode(env, agent):\n",
    "    total_reward = 0\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        action = agent.predict(obs)  # greedy\n",
    "        next_obs, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        obs = next_obs\n",
    "        time.sleep(0.5)\n",
    "        env.render()\n",
    "        if done:\n",
    "            print('test reward = %.1f' % (total_reward))\n",
    "            break\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = gym.make(\n",
    "        \"FrozenLake-v0\", is_slippery=False)  # 0 left, 1 down, 2 right, 3 up\n",
    "    env = FrozenLakeWapper(env)\n",
    "\n",
    "    agent = QLearningAgent(\n",
    "        obs_n=env.observation_space.n,\n",
    "        act_n=env.action_space.n,\n",
    "        learning_rate=0.1,\n",
    "        gamma=0.9,\n",
    "        e_greed=0.1)\n",
    "\n",
    "    for episode in range(500):\n",
    "        ep_reward, ep_steps = run_episode(env, agent)\n",
    "        print('Episode %s: steps = %s , reward = %.1f' % (episode, ep_steps,\n",
    "                                                          ep_reward))\n",
    "\n",
    "    # 训练结束，查看算法效果\n",
    "    test_episode(env, agent)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea758ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
